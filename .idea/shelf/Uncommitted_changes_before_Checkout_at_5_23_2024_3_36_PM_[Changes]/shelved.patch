Index: anhduc.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#anh duc code tren file nay\r\n\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.svm import LinearSVC\r\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\r\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n\r\ntrain = pd.read_csv('data/train.csv')\r\ntest = pd.read_csv('data/test.csv')\r\nX_target0 = train[train.target == 0].sample(frac=0.9)  # Lấy mẫu ngẫu nhiên từ lớp 0\r\nX_target1 = train[train.target == 1].sample(frac=0.9)  # Lớp 1\r\n\r\nprint(\"Tổng số dữ liệu trong tập train: \",train.shape[0])\r\nprint(\"Số câu hỏi bình thường: \", len(train[train.target == 0]))\r\nprint(\"Số câu hỏi toxic: \",len(train[train.target == 1]))\r\nprint(\"Tỉ lệ giữa 2 lớp: \",len(train[train.target == 1])/len(train[train.target == 0]))\r\n\r\n#Hàm dự đoán sử dụng linear\r\ntfidf = TfidfVectorizer(ngram_range=(1, 3))\r\ndef predict_linearSVC(X_train, y_train, X_test):\r\n    tfidf.fit(X_train)\r\n    X_train_tfidf = tfidf.transform(X_train)\r\n    X_test_tfidf = tfidf.transform(X_test)\r\n    weights = {}\r\n    weights[0] = len(X_target0) / 2 * len(X_train)\r\n    weights[1] = len(X_target1) / 2 * len(X_train)\r\n    y = [0, 1]\r\n    class_weight = {val: weights[index] for index, val in enumerate(y)}\r\n    svm = LinearSVC()\r\n    svm.fit(X_train_tfidf, y_train)\r\n    train_predictions = svm.predict(X_train_tfidf)\r\n    test_predictions = svm.predict(X_test_tfidf)\r\n    return train_predictions, test_predictions\r\n\r\n# Dự đoán trên tập validation\r\n# def validate_base_model():\r\n#     train = pd.read_csv('data/train.csv')\r\n#     train = train.dropna(subset=['question_text'])\r\n#     X = train.question_text\r\n#     y = train.target\r\n#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n#     train_predictions, test_predictions= predict_linearSVC(X_train, y_train, X_test)\r\n#     train_accuracy = accuracy_score(y_train, train_predictions)\r\n#     test_accuracy = accuracy_score(y_test, test_predictions)\r\n#     f1 = f1_score(y_test, test_predictions)\r\n#     print(f\"Train Accuracy: {train_accuracy}\")\r\n#     print(f\"Validation Accuracy: {test_accuracy}\")\r\n#     return f1\r\n\r\ndef validate_undersampling():\r\n    data = pd.concat([X_target0, X_target1])  # Nối hai DataFrame lại với nhau\r\n    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\r\n    data_augmented = pd.concat([X_target0, X_target1, X_target1, X_target1, X_target1]) # Lặp lại dữ liệu nhãn 1 4 lần\r\n    data_augmented = data_augmented.sample(frac=1, random_state=42).reset_index(drop=True)\r\n    X = data_augmented.question_text\r\n    y = data_augmented.target\r\n\r\n    remaining_data = train.drop(data.index) # Lấy phần data chưa dùng để train từ tập train gốc để test\r\n    remaining_data = remaining_data.sample(frac=1, random_state=42).reset_index(drop=True)\r\n    X_test = remaining_data.question_text\r\n    y_test = remaining_data.target\r\n\r\n    train_predictions, test_predictions = predict_linearSVC(X, y, X_test)\r\n\r\n    train_accuracy = accuracy_score(y, train_predictions)\r\n    test_accuracy = accuracy_score(y_test, test_predictions)\r\n    train_precision = precision_score(y, train_predictions)\r\n    test_precision = precision_score(y_test, test_predictions)\r\n    train_recall = recall_score(y, train_predictions)\r\n    test_recall = recall_score(y_test, test_predictions)\r\n    f1 = f1_score(y_test, test_predictions)\r\n\r\n\r\n    tn, fp, fn, tp = confusion_matrix(y_test, test_predictions).ravel()\r\n    precision1_score = tp / (tp + fp)\r\n    recall1_score = tp / (tp + fn)\r\n    print(\"Precision score\", precision1_score)\r\n    print(\"Recall score\", recall1_score)\r\n\r\n    print(\"Train Accuracy: \", train_accuracy)\r\n    print(\"Validation Accuracy: \", test_accuracy)\r\n    print(\"Train Precision: \", train_precision)\r\n    print(\"Validation Precision: \", test_precision)\r\n    print(\"Train Recall: \", train_recall)\r\n    print(\"Validation Recall: \", test_recall)\r\n\r\n    return f1\r\n\r\nprint(\"F1-Score với Under Sampling: \", validate_undersampling())\r\n# print('F1-Score của base-model trên tập validation: ',validate_base_model())
===================================================================
diff --git a/anhduc.py b/anhduc.py
--- a/anhduc.py	
+++ b/anhduc.py	
@@ -50,7 +50,7 @@
 def validate_undersampling():
     data = pd.concat([X_target0, X_target1])  # Nối hai DataFrame lại với nhau
     data = data.sample(frac=1, random_state=42).reset_index(drop=True)
-    data_augmented = pd.concat([X_target0, X_target1, X_target1, X_target1, X_target1]) # Lặp lại dữ liệu nhãn 1 4 lần
+    data_augmented = pd.concat([data, X_target1, X_target1, X_target1]) # Lặp lại dữ liệu nhãn 1 4 lần
     data_augmented = data_augmented.sample(frac=1, random_state=42).reset_index(drop=True)
     X = data_augmented.question_text
     y = data_augmented.target
